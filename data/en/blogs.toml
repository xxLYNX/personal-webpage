[[blogs]]
  title = "Attention Is Not All You Need. It's How You Need It."
  date = "2025-09-07"
  summary = "Jet-Nemotron rethinks AI by using attention only when necessary, dramatically boosting speed and accuracy compared to traditional full-attention models."
  link = "https://blog.example.com/post1"
  tags = ["AI", "Machine Learning", "Transformers"]

[[blogs]]
  title = "Are LLMs Needlessly Huge? Extreme Compression of LLMs using Quantum Inspired Tensor Networks"
  date = "2025-08-23"
  summary = "Presents a novel approach called CompactifAI by Multiverse Computing, which uses quantum-inspired tensor networks to drastically compress LLMs with minimal loss in accuracy."
  link = "https://blog.example.com/post2"
  tags = ["LLM", "Compression", "Quantum Computing"]

[[blogs]]
  title = "How AI Models Train on Private Data Without Accessing It: Federated Learning Explained"
  date = "2025-08-16"
  summary = "Federated Learning (FL) enables AI models to be trained on distributed data without centralizing sensitive information. Instead of collecting data in one location, FL sends model copies to local devices where they train on private data."
  link = "https://blog.example.com/post3"
  tags = ["Federated Learning", "Privacy", "AI"]
